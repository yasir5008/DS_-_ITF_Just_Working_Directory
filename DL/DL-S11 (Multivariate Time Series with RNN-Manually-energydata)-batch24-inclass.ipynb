{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "# ^^^ pyforest auto-imports - don't write above this line\n",
    "___\n",
    "\n",
    "<p style=\"text-align: center;\"><img src=\"https://docs.google.com/uc?id=1lY0Uj5R04yMY3-ZppPWxqCr5pvBLYPnV\" class=\"img-fluid\" alt=\"CLRSWY\"></p>\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\">Deep Learning<br><br>Session - 11<br><br>Multivariate Time Series Forecasting with RNN<br><br>(Manually)<br><h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appliance Energy Usage: A Multivariate Time Series Forecasting Example\n",
    "\n",
    "Experimental data used to create regression models of appliances energy use in a low energy building.\n",
    "Data Set Information:\n",
    "\n",
    "The data set is at 10 min for about 4.5 months. The house temperature and humidity conditions were monitored with a ZigBee wireless sensor network. Each wireless node transmitted the temperature and humidity conditions around 3.3 min. Then, the wireless data was averaged for 10 minutes periods. The energy data was logged every 10 minutes with m-bus energy meters. Weather from the nearest airport weather station (Chievres Airport, Belgium) was downloaded from a public data set from Reliable Prognosis (rp5.ru), and merged together with the experimental data sets using the date and time column. Two random variables have been included in the data set for testing the regression models and to filter out non predictive attributes (parameters).\n",
    "Original source of the dataset:\n",
    "\n",
    "http://archive.ics.uci.edu/ml/datasets/Appliances+energy+prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- date time year-month-day hour:minute:second\n",
    "- Appliances, energy use in Wh\n",
    "- lights, energy use of light fixtures in the house in Wh\n",
    "- T1, Temperature in kitchen area, in Celsius\n",
    "- RH_1, Humidity in kitchen area, in %\n",
    "- T2, Temperature in living room area, in Celsius\n",
    "- RH_2, Humidity in living room area, in %\n",
    "- T3, Temperature in laundry room area\n",
    "- RH_3, Humidity in laundry room area, in %\n",
    "- T4, Temperature in office room, in Celsius\n",
    "- RH_4, Humidity in office room, in %\n",
    "- T5, Temperature in bathroom, in Celsius\n",
    "- RH_5, Humidity in bathroom, in %\n",
    "- T6, Temperature outside the building (north side), in Celsius\n",
    "- RH_6, Humidity outside the building (north side), in %\n",
    "- T7, Temperature in ironing room , in Celsius\n",
    "- RH_7, Humidity in ironing room, in %\n",
    "- T8, Temperature in teenager room 2, in Celsius\n",
    "- RH_8, Humidity in teenager room 2, in %\n",
    "- T9, Temperature in parents room, in Celsius\n",
    "- RH_9, Humidity in parents room, in %\n",
    "- To, Temperature outside (from Chievres weather station), in Celsius\n",
    "- Pressure (from Chievres weather station), in mm Hg\n",
    "- RH_out, Humidity outside (from Chievres weather station), in %\n",
    "- Wind speed (from Chievres weather station), in m/s\n",
    "- Visibility (from Chievres weather station), in km\n",
    "- Tdewpoint (from Chievres weather station), Â°C\n",
    "- rv1, Random variable 1, nondimensional\n",
    "- rv2, Random variable 2, nondimensional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.warn(\"this will not show\")\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,6)\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "# Set it None to display all rows in the dataframe\n",
    "# pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Set it to None to display all columns in the dataframe\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recognizing and Understanding Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data&resources/energydata_complete.csv',index_col='date', parse_dates = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15))\n",
    "sns.heatmap(df.corr(), annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "- Let's reduce the number of feature\n",
    "- Let's resample the dataset by hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.rename(columns = {'T6':'T_outside', 'RH_6':'RH_outside'})\n",
    "df[\"T_inside\"] = (df[\"T1\"] + df[\"T2\"] + df[\"T3\"] + df[\"T4\"] + df[\"T5\"] + df[\"T7\"] + df[\"T8\"] + df[\"T9\"])/8\n",
    "df[\"RH_inside\"] = (df[\"RH_1\"] + df[\"RH_2\"] + df[\"RH_3\"] + df[\"RH_4\"] + df[\"RH_5\"] + df[\"RH_7\"] + df[\"RH_8\"] + df[\"RH_9\"])/8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = ['T1', 'RH_1', 'T2', 'RH_2', 'T3', 'RH_3', 'T4', 'RH_4', 'T5', 'RH_5',\n",
    "             'T7', 'RH_7', 'T8', 'RH_8', 'T9', 'RH_9', 'T_out', 'RH_out', 'rv1', 'rv2']\n",
    "df.drop(drop_list, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a = df[[\"Appliances\", \"lights\"]]\n",
    "df_b = df.drop([\"Appliances\", \"lights\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a = df_a.resample(\"H\").sum()\n",
    "df_b = df_b.resample(\"H\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_a, df_b], axis =1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also round off the data, to one decimal point precision, otherwise this may cause issues with our network (we will also normalize the data anyways, so this level of precision isn't useful to us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15))\n",
    "sns.heatmap(df.corr(), annot=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Appliances'].plot(figsize=(18,6))\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Appliances'].loc[\"2016-05-01 00:00:00\" : \"2016-05-03 23:00:00\"].plot(figsize=(18,6))\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many rows per day?\n",
    "24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_days = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ind = test_days*24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.iloc[:-test_ind]\n",
    "test = df.iloc[-test_ind:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_columns = df.columns[1:]\n",
    "\n",
    "f_transformer = RobustScaler()\n",
    "target_transformer = RobustScaler()\n",
    "\n",
    "train.loc[:, f_columns] = f_transformer.fit_transform(train[f_columns])\n",
    "train['Appliances'] = target_transformer.fit_transform(train[['Appliances']])\n",
    "\n",
    "test.loc[:, f_columns] = f_transformer.transform(test[f_columns])\n",
    "test['Appliances'] = target_transformer.transform(test[['Appliances']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a Function for Creating Time Steps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(X, y, time_steps=1):\n",
    "    \"\"\" Create data sequence\n",
    "    \n",
    "    Arguments:\n",
    "        * X: time-series data\n",
    "        * y: target value\n",
    "        * time_steps: Used to create input sequence of timesteps\n",
    "    \n",
    "    Returns:\n",
    "        * input_sequence: Numpy array of sequences of time-series data\n",
    "        * output: Numpy array of output i.e. next value for respective sequence\n",
    "    \n",
    "    \"\"\"\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        v = X.iloc[i:(i + time_steps)].values\n",
    "        Xs.append(v)        \n",
    "        ys.append(y.iloc[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = 24\n",
    "\n",
    "# reshape to [samples, time_steps, n_features]\n",
    "\n",
    "X_train, y_train = create_dataset(train, train.Appliances, time_steps)\n",
    "X_test, y_test = create_dataset(test, test.Appliances, time_steps)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building with LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Bidirectional, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Bidirectional(LSTM(units=100, input_shape=(time_steps, n_features))))\n",
    "\n",
    "#model.add(Dropout(rate=0.2))\n",
    "\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor = 'val_loss', patience = 5, restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, \n",
    "          epochs=30, \n",
    "          batch_size=24, \n",
    "          validation_split=0.3,\n",
    "#          shuffle=False,\n",
    "          callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = pd.DataFrame(model.history.history)\n",
    "losses.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(actual, pred):\n",
    "    rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "    mae = mean_absolute_error(actual, pred)\n",
    "    mse = mean_squared_error(actual, pred)\n",
    "    score = r2_score(actual, pred)\n",
    "    return print(\"r2_score:\", score, \"\\nmae:\", mae, \"\\nmse:\",mse, \"\\nrmse:\",rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First way : after each prediction, reel value will be used for next prediction¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverse Transformation and Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_inv = target_transformer.inverse_transform(y_train.reshape(1, -1))\n",
    "y_test_inv = target_transformer.inverse_transform(y_test.reshape(1, -1))\n",
    "y_pred_inv = target_transformer.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_index = test.iloc[time_steps:].index\n",
    "\n",
    "pred_test = pd.concat([pd.DataFrame(y_test_inv.reshape(-1, 1)),\n",
    "                       pd.DataFrame(y_pred_inv)], axis = 1)\n",
    "pred_test.columns=['test','prediction']\n",
    "pred_test.index = test_index\n",
    "pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(np.arange(0, len(y_train)), y_train_inv.flatten(), 'g', label=\"history\")\n",
    "plt.plot(np.arange(len(y_train), len(y_train) + len(y_test)), y_test_inv.flatten(), marker='.', label=\"true\")\n",
    "plt.plot(np.arange(len(y_train), len(y_train) + len(y_test)), y_pred_inv.flatten(), 'r', label=\"prediction\")\n",
    "plt.ylabel('Bike Count')\n",
    "plt.xlabel('Time Step')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(y_test_inv.flatten(), marker='.', label=\"true\")\n",
    "plt.plot(y_pred_inv.flatten(), 'r', label=\"prediction\")\n",
    "plt.ylabel('Bike Count')\n",
    "plt.xlabel('Time Step')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second way : after each prediction, result will be used for next prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake = test.iloc[:time_steps,1:]\n",
    "df_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reel = np.array(test.iloc[:time_steps,:1])\n",
    "reel.reshape((1,-1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake.values.reshape((df_fake.shape[0], 1, df_fake.shape[1])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_scaled = []\n",
    "\n",
    "first_eval_batch = train.values[-time_steps:]\n",
    "current_batch = first_eval_batch.reshape((1, time_steps, n_features))\n",
    "features = df_fake.values.reshape((df_fake.shape[0], 1, df_fake.shape[1]))\n",
    "\n",
    "for i in range(time_steps):\n",
    "    \n",
    "    # get prediction 1 time stamp ahead\n",
    "    current_pred = model.predict(current_batch)\n",
    "    \n",
    "    # store prediction\n",
    "    predictions_scaled.append(current_pred[0])\n",
    "    new = features[i][0].tolist()\n",
    "    new.insert(0,current_pred[0][0])\n",
    "    new = np.array(new).reshape(1,1,n_features)\n",
    "    \n",
    "    # update batch to now include prediction and drop first value\n",
    "    current_batch = np.append(current_batch[:, 1:, :], new, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metrics(reel, predictions_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverse Transformation and Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = target_transformer.inverse_transform(predictions_scaled)\n",
    "reel = target_transformer.inverse_transform(reel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare = pd.DataFrame(data = reel, index = test.index[:time_steps], columns = [\"reel\"])\n",
    "compare[\"prediction\"] = predictions\n",
    "compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrain and Forecasting with Full Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_columns = df_scaled.columns[1:]\n",
    "\n",
    "f_transformer = RobustScaler()\n",
    "target_transformer = RobustScaler()\n",
    "\n",
    "df_scaled.loc[:, f_columns] = f_transformer.fit_transform(df_scaled[f_columns])\n",
    "df_scaled['Appliances'] = target_transformer.fit_transform(df_scaled[['Appliances']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's devide dataset as \"full\" and \"val\". We can think about this \"val\" data as the weather forecast of next days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size = 24\n",
    "val = df_scaled.iloc[-val_size:]\n",
    "full = df_scaled.iloc[:-val_size]\n",
    "print(len(full), len(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reshape to [samples, time_steps, n_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = create_dataset(full, full.Appliances, time_steps)\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Final model with full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Bidirectional(LSTM(units=100, input_shape=(time_steps, n_features))))\n",
    "\n",
    "#model.add(Dropout(rate=0.2))\n",
    "\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y, \n",
    "          epochs=15, \n",
    "          batch_size=24, \n",
    "         # shuffle=False\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = pd.DataFrame(model.history.history)\n",
    "losses.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake = val.iloc[:,1:]\n",
    "df_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reel = np.array(val.iloc[:,:1])\n",
    "reel.reshape((1,-1))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First way : after each prediction, reel value will be use for next prediction¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = []\n",
    "# Replace periods with whatever forecast length you want\n",
    "periods = 24\n",
    "\n",
    "first_eval_batch = full.values[-time_steps:]\n",
    "current_batch = first_eval_batch.reshape((1, time_steps, full.shape[1]))\n",
    "features = df_fake.values.reshape((df_fake.shape[0], 1, df_fake.shape[1]))\n",
    "\n",
    "for i in range(periods):\n",
    "    \n",
    "    # get prediction 1 time stamp ahead \n",
    "    current_pred = model.predict(current_batch)[0][0]\n",
    "    \n",
    "    # store prediction\n",
    "    forecast.append(current_pred) \n",
    "    new = features[i][0].tolist()\n",
    "    new.insert(0,reel[i][0])\n",
    "    new = np.array(new).reshape(1,1,full.shape[1])\n",
    "    \n",
    "    # update batch to now include prediction and drop first value\n",
    "    current_batch = np.append(current_batch[:, 1:, :], new, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eval_metrics(reel.reshape((1,-1))[0], forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = target_transformer.inverse_transform(np.array(forecast).reshape(1,-1))\n",
    "forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_index = pd.date_range(start = '2016-05-26 19:00:00', periods = periods, freq = 'H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_df = pd.DataFrame(data = forecast.reshape(-1, 1), index = forecast_index, columns = ['Forecast'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df[\"Appliances\"].plot()\n",
    "forecast_df.plot(ax = ax, figsize = (16, 8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df[\"Appliances\"].plot()\n",
    "forecast_df.plot(ax = ax, figsize = (16, 8))\n",
    "plt.xlim('2016-05-24 19:00:00', '2016-05-27 18:00:00')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second way : after each prediction, result will be use for next prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = []\n",
    "# Replace periods with whatever forecast length you want\n",
    "periods = 24\n",
    "\n",
    "first_eval_batch = full.values[-time_steps:]\n",
    "current_batch = first_eval_batch.reshape((1, time_steps, full.shape[1]))\n",
    "features = df_fake.values.reshape((df_fake.shape[0], 1, df_fake.shape[1]))\n",
    "\n",
    "for i in range(periods):\n",
    "    \n",
    "    # get prediction 1 time stamp ahead \n",
    "    current_pred = model.predict(current_batch)[0][0]\n",
    "    \n",
    "    # store prediction\n",
    "    forecast.append(current_pred) \n",
    "    new = features[i][0].tolist()\n",
    "    new.insert(0,current_pred)\n",
    "    new = np.array(new).reshape(1,1,full.shape[1])\n",
    "    \n",
    "    # update batch to now include prediction and drop first value\n",
    "    current_batch = np.append(current_batch[:, 1:, :], new, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metrics(reel.reshape((1,-1))[0], forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = target_transformer.inverse_transform(np.array(forecast).reshape(1,-1))\n",
    "forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_index = pd.date_range(start = '2016-05-26 19:00:00', periods = periods, freq = 'H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_df = pd.DataFrame(data = forecast.reshape(-1, 1), index = forecast_index, columns = ['Forecast'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df[\"Appliances\"].plot()\n",
    "forecast_df.plot(ax = ax, figsize = (16, 8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax = df[\"Appliances\"].plot()\n",
    "forecast_df.plot(ax = ax, figsize = (16, 8))\n",
    "plt.xlim('2016-05-24 19:00:00', '2016-05-27 18:00:00')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center\"><img src=\"https://docs.google.com/uc?id=1lY0Uj5R04yMY3-ZppPWxqCr5pvBLYPnV\" class=\"img-fluid\" alt=\"CLRSWY\"></p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
